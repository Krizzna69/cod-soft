{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtLjKUZp9UxXWiMMpQcPlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krizzna69/cod-soft/blob/main/sms_spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jlcduZgWASKF"
      },
      "outputs": [],
      "source": [
        "import numpy as np        # For numerical operations\n",
        "import pandas as pd       # For data manipulation and analysis\n",
        "import matplotlib.pyplot as plt  # For data visualization\n",
        "import seaborn as sns       # For data visualization\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# handling imbalanced datasets and performing resampling techniques\n",
        "import imblearn\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "data = pd.read_csv('/content/sms-spam-collection-dataset/spam.csv', encoding='latin1')\n",
        "data.head()\n",
        "\n",
        "data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "\n",
        "data.info()\n",
        "\n",
        "data.rename(columns = {'v1': 'target', 'v2': 'Message'}, inplace = True)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "en = LabelEncoder()\n",
        "data['target'] = en.fit_transform(data['target'])\n",
        "\n",
        "data.head()\n",
        "\n",
        "data = data.drop_duplicates(keep = 'first')\n",
        "l = data['target'].value_counts()\n",
        "colors = ['#8BC34A','#B2EBF2']\n",
        "\n",
        "fig = plt.subplots(nrows = 1,ncols = 2,figsize = (20,5))\n",
        "plt.subplot(1,2,1)\n",
        "l.plot.pie(explode=[0,0.1],autopct='%1.1f%%',shadow=True, labels=['Ham', 'Spam'], colors=colors)\n",
        "plt.title('Target (%)')\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "ax = sns.countplot(x='target',data = data, palette = colors,edgecolor = 'black', width=0.4)\n",
        "for rect in ax.patches:\n",
        "    ax.text(rect.get_x() + rect.get_width() / 2, rect.get_height(), rect.get_height(), horizontalalignment='center', fontsize = 11)\n",
        "ax.set_xticklabels(['Ham', 'Spam'])\n",
        "plt.title('Number of Target')\n",
        "plt.show()\n",
        "\n",
        "x = data['Message']\n",
        "y = data['target']\n",
        "\n",
        "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase=True)\n",
        "\n",
        "x_extraction = feature_extraction.fit_transform(x)\n",
        "\n",
        "print(x_extraction)\n",
        "\n",
        "# Performing oversampling and undersampling using SMOTE and RandomUnderSampler techniques to address class imbalance\n",
        "\n",
        "over = SMOTE(sampling_strategy = 1)\n",
        "under = RandomUnderSampler(sampling_strategy = 0.4)\n",
        "f1 = x_extraction\n",
        "t1 = y\n",
        "\n",
        "steps = [('under', under),('over', over)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "f1, t1 = pipeline.fit_resample(f1, t1)\n",
        "Counter(t1)\n",
        "\n",
        "# data splitting, model evaluation metrics, cross-validation, hyperparameter tuning, and classification performance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "# necessary classifiers for building machine learning models\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(f1, t1, test_size=0.3, random_state=101)\n",
        "\n",
        "\n",
        "# Defining a function to train and evaluate a machine learning classifier model\n",
        "\n",
        "def model(classifier,x_train,y_train,x_test,y_test):\n",
        "\n",
        "    classifier.fit(x_train,y_train)\n",
        "    prediction = classifier.predict(x_test)\n",
        "    cv = RepeatedStratifiedKFold(n_splits = 10,n_repeats = 3,random_state = 1)\n",
        "    print(\"Cross Validation Score : \",'{0:.2%}'.format(cross_val_score(classifier,x_train,y_train,cv = cv,scoring = 'roc_auc').mean()))\n",
        "    print(\"ROC_AUC Score : \",'{0:.2%}'.format(roc_auc_score(y_test,prediction)))\n",
        "\n",
        "\n",
        "\n",
        "# Defining a function to evaluate the performance of a machine learning classifier model\n",
        "def model_evaluation(classifier,x_test,y_test):\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test,classifier.predict(x_test))\n",
        "    names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    counts = [value for value in cm.flatten()]\n",
        "    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
        "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(names,counts,percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(cm,annot = labels,cmap = colors,fmt ='')\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test,classifier.predict(x_test)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Defining a function to plot the Receiver Operating Characteristic (ROC) curve\n",
        "def plot_roc_curve(y_true, y_scores):\n",
        "    # Calculate the false positive rate (FPR) and true positive rate (TPR)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "\n",
        "    # Calculate the area under the ROC curve (AUC)\n",
        "    auc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(auc))\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line (random classifier)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Initializing an XGBoost classifier with specific hyperparameters\n",
        "\n",
        "classifier_xgb = XGBClassifier(learning_rate= 0.01,max_depth = 3,n_estimators = 1000)\n",
        "\n",
        "\n",
        "# Training, evaluating, and evaluating the performance of an XGBoost classifier model\n",
        "\n",
        "model(classifier_xgb,x_train,y_train,x_test,y_test)\n",
        "model_evaluation(classifier_xgb,x_test,y_test)\n",
        "\n",
        "# Making predictions using the XGBoost classifier and plotting the ROC curve\n",
        "\n",
        "prediction_xgb = classifier_xgb.predict(x_test)\n",
        "plot_roc_curve(y_test, prediction_xgb)# Initializing a Logistic Regression classifier with specific hyperparameters\n",
        "\n",
        "classifier_lr = LogisticRegression(random_state = 0,C=10,penalty= 'l2')# Training, evaluating, and evaluating the performance of a Logistic Regression classifier model\n",
        "\n",
        "model(classifier_lr,x_train,y_train,x_test,y_test)\n",
        "model_evaluation(classifier_lr,x_test,y_test)# Making predictions using the Logistic Regression classifier and plotting the ROC curve\n",
        "\n",
        "prediction_lr = classifier_lr.predict(x_test)\n",
        "plot_roc_curve(y_test, prediction_lr)\n",
        "\n",
        "classifier_svc = SVC(kernel = 'linear',C = 0.1)\n",
        "\n",
        "model(classifier_svc,x_train,y_train,x_test,y_test)\n",
        "model_evaluation(classifier_svc,x_test,y_test)\n",
        "\n",
        "prediction_svc = classifier_svc.predict(x_test)\n",
        "plot_roc_curve(y_test, prediction_svc)\n",
        "\n",
        "classifier_rf = RandomForestClassifier(max_depth = 4,random_state = 0)\n",
        "prediction_rf = classifier_rf.predict(x_test)\n",
        "plot_roc_curve(y_test, prediction_rf)\n",
        "\n",
        "classifier_knn = KNeighborsClassifier(leaf_size = 1, n_neighbors = 3,p = 1)\n",
        "\n",
        "model(classifier_knn,x_train,y_train,x_test,y_test)\n",
        "model_evaluation(classifier_knn,x_test,y_test)\n",
        "\n",
        "\n",
        "prediction_knn = classifier_knn.predict(x_test)\n",
        "plot_roc_curve(y_test, prediction_knn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5AACXIWAWK2"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}